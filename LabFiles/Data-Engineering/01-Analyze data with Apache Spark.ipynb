{"cells":[{"cell_type":"markdown","source":["## Lab__01-Analyze data with Apache Spark\n","\n","###### 1. Create Workspace\n","###### 2. Create Lakehouse\n","###### 3. Set Default Lakehouse"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"b4e9fd61-6ad3-4353-962d-f5ee59dadedb"},{"cell_type":"code","source":["#####################################\n","# spark best practice\n","#####################################\n","spark.conf.set(\"spark.sql.parquet.vorder.enabled\", \"true\")\n","spark.conf.set(\"spark.microsoft.delta.optimizationWrite.enabled\", \"true\")\n","spark.conf.set(\"spark.microsoft.delta.optimizationWrite.binSize\", \"1073741824\")\n","spark.conf.set('spark.ms.autotune.queryTuning.enabled', 'true')\n","spark.conf.set('spark.sql.files.maxPartitionBytes', '1073741824')"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"47097f89-716d-4798-83d7-dd641e50d387"},{"cell_type":"code","source":["#####################################\n","# Download Example files \n","#####################################\n","import os\n","import requests\n","import zipfile\n","\n","DATA_ROOT = \"/lakehouse/default\"\n","DATA_FOLDER = \"Files/orders\"  # folder with data files\n","DATA_FILE = \"orders.zip\"  # data file name\n","\n","os.makedirs(f'{DATA_ROOT}/{DATA_FOLDER}', exist_ok=True)\n","remote_url = \"https://github.com/MicrosoftLearning/dp-data/raw/main/orders.zip\"\n","\n","r = requests.get(remote_url, timeout=30)\n","with open(f'{DATA_ROOT}/{DATA_FOLDER}/{DATA_FILE}', 'wb') as f:\n","    f.write(r.content)\n","\n","with zipfile.ZipFile(f'{DATA_ROOT}/{DATA_FOLDER}/{DATA_FILE}', mode='r') as zipf:\n","    for subfile in zipf.namelist():\n","        zipf.extract(subfile, f'{DATA_ROOT}/{DATA_FOLDER}/')\n","\n","os.remove(f'{DATA_ROOT}/{DATA_FOLDER}/{DATA_FILE}')"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"439f837f-709c-4723-8bcf-25358a5c525c"},{"cell_type":"code","source":["df = spark.read.format(\"csv\").option(\"header\",\"false\").load(\"Files/orders/2019.csv\")\n","display(df)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"collapsed":false},"id":"3c810348-b297-4c2e-89b8-df1d6d1bfd58"},{"cell_type":"code","source":["#####################################\n","#create dataframe with Schema\n","#####################################\n","from pyspark.sql.types import *\n","\n","orderSchema = StructType([\n","    StructField(\"SalesOrderNumber\", StringType()),\n","    StructField(\"SalesOrderLineNumber\", IntegerType()),\n","    StructField(\"OrderDate\", DateType()),\n","    StructField(\"CustomerName\", StringType()),\n","    StructField(\"Email\", StringType()),\n","    StructField(\"Item\", StringType()),\n","    StructField(\"Quantity\", IntegerType()),\n","    StructField(\"UnitPrice\", FloatType()),\n","    StructField(\"Tax\", FloatType())\n","    ])\n","\n","df = spark.read.format(\"csv\").schema(orderSchema).load(\"Files/orders/*.csv\")\n","display(df)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"collapsed":false},"id":"ebcd6563-3742-4054-9f8b-c51e7d07790a"},{"cell_type":"code","source":["customers = df['CustomerName', 'Email']\n","print(customers.count())\n","print(customers.distinct().count())\n","display(customers.distinct())"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"collapsed":false},"id":"94f40f19-edd2-417d-94a8-af4b158d0eb7"},{"cell_type":"code","source":["#####################################\n","#select dataframe with filter\n","#####################################\n","customers = df.select(\"CustomerName\", \"Email\").where(df['Item']=='Road-250 Red, 52')\n","print(customers.count())\n","print(customers.distinct().count())\n","display(customers.distinct())"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"collapsed":false},"id":"440f4260-1fd1-42e8-96e9-3ba0e9bbb10e"},{"cell_type":"code","source":["#####################################\n","#Aggregate and group data in a dataframe\n","#####################################\n","productSales = df.select(\"Item\", \"Quantity\").groupBy(\"Item\").sum()\n","display(productSales)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"collapsed":false},"id":"2770f2b0-c652-4edf-b6be-90587afcc254"},{"cell_type":"code","source":["#####################################\n","#groupby, orderby in a dataframe\n","#####################################\n","from pyspark.sql.functions import *\n","\n","yearlySales = df.select(year(col(\"OrderDate\")).alias(\"Year\")).groupBy(\"Year\").count().orderBy(\"Year\")\n","display(yearlySales)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"collapsed":false},"id":"5b11485c-da8c-4772-bc38-d3786542a916"},{"cell_type":"code","source":["#####################################\n","#Use dataframe methods and functions to transform data (Option: Data Wrangler)\n","#####################################\n","from pyspark.sql.functions import *\n","\n","## Create Year and Month columns\n","transformed_df = df.withColumn(\"Year\", year(col(\"OrderDate\"))).withColumn(\"Month\", month(col(\"OrderDate\")))\n","\n","# Create the new FirstName and LastName fields\n","transformed_df = transformed_df.withColumn(\"FirstName\", split(col(\"CustomerName\"), \" \").getItem(0)).withColumn(\"LastName\", split(col(\"CustomerName\"), \" \").getItem(1))\n","\n","# Filter and reorder columns\n","transformed_df = transformed_df[\"SalesOrderNumber\", \"SalesOrderLineNumber\", \"OrderDate\", \"Year\", \"Month\", \"FirstName\", \"LastName\", \"Email\", \"Item\", \"Quantity\", \"UnitPrice\", \"Tax\"]\n","\n","# Display the first five orders\n","display(transformed_df.limit(5))"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"collapsed":false},"id":"dc347873-c113-4afe-83b3-e9bf4b4beba0"},{"cell_type":"code","source":["#####################################\n","#Save the transformed data\n","#####################################\n","transformed_df.write.mode(\"overwrite\").parquet('Files/transformed_data/orders')\n","#print (\"Transformed data saved!\")\n","\n","#####################################\n","#Read parquet file\n","#####################################\n","orders_df = spark.read.format(\"parquet\").load(\"Files/transformed_data/orders\")\n","display(orders_df)\n"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"collapsed":false},"id":"44ccea29-3d6a-4664-bcea-affc8a8c2ffb"},{"cell_type":"code","source":["#####################################\n","#Save the transformed data by partitioined files\n","#####################################\n","orders_df.write.partitionBy(\"Year\",\"Month\").mode(\"overwrite\").parquet(\"Files/partitioned_data\")\n","print (\"Transformed data saved!\")\n","\n","orders_2021_df = spark.read.format(\"parquet\").load(\"Files/partitioned_data/Year=2021/Month=*\")\n","display(orders_2021_df)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"collapsed":false},"id":"f2fd0718-8113-4e9f-8e20-1f8dad773b46"},{"cell_type":"code","source":["#####################################\n","# Create a new table (default format : delta)\n","#####################################\n","df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"salesorders\")\n","\n","# Get the table description\n","spark.sql(\"DESCRIBE EXTENDED salesorders\").show(truncate=False)\n"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"7cadbcdc-1217-4ed1-aab3-e54546638b56"},{"cell_type":"code","source":["#####################################\n","# DESCRIBE DETAIL\n","#####################################\n","from pyspark.sql.functions import lit\n","\n","lakehouse = \"lakehouse\"\n","tablename = \"salesorders\"\n","detail_df = spark.sql(f\"DESCRIBE DETAIL {lakehouse}.{tablename}\")\n","detail_df = detail_df.withColumn(\"lakehousename\", lit(lakehouse)).withColumn(\"tablename\", lit(tablename))\n","\n","history_df = spark.sql(f\"DESCRIBE HISTORY {lakehouse}.{tablename}\")\n","history_df = history_df.withColumn(\"lakehousename\", lit(lakehouse)).withColumn(\"tablename\", lit(tablename))\n","\n","join = detail_df.join(history_df, ['lakehousename','tablename'])\n","\n","display(join)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"66998af3-5835-4527-b637-62fd8fea96db"},{"cell_type":"code","source":["df = spark.sql(\"SELECT * FROM lakehouse.salesorders LIMIT 1000\")\n","display(df)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"collapsed":false},"id":"e41aa23f-5868-4ed9-a3cb-bb0f6afda899"},{"cell_type":"code","source":["#########################################\n","# Partitioning\n","#https://learn.microsoft.com/en-us/fabric/data-engineering/tutorial-lakehouse-data-preparation\n","#########################################\n","from pyspark.sql.functions import col, year, month, quarter\n","\n","table_name = 'salesorders_Partition'\n","\n","df = spark.sql(\"SELECT * FROM lakehouse.salesorders\")\n","df = df.withColumn('Year', year(col(\"OrderDate\")))\n","df = df.withColumn('Month', month(col(\"OrderDate\")))\n","\n","#display(df)\n","\n","df.write.mode(\"overwrite\").format(\"delta\").partitionBy(\"Year\",\"Month\").save(\"Tables/\" + table_name)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"687f749a-95a8-483c-adf2-3ed0e60012a3"},{"cell_type":"code","source":["%%sql\n","-----------------------------------------------\n","-- Partitioning by SparkSQL\n","-----------------------------------------------\n","CREATE or REPLACE TABLE lakehouse.salesorders_partition_128\n","(\n","    SalesOrderLineNumber BIGINT\n","    , OrderDate DATE\n","    , Quantity BIGINT\n","    , UnitPrice FLOAT\n","    , Year INT\n","    , Month INT\n",")USING DELTA\n","PARTITIONED BY(Year, Month)\n","TBLPROPERTIES('delta.targetFileSize' = '128mb');\n","\n","SET spark.sql.sources.partitionOverwriteMode=dynamic;\n","SET spark.sql.enable.concurrentWrites=true;\n","\n","INSERT OVERWRITE TABLE lakehouse.salesorders_partition_128\n","    SELECT SalesOrderLineNumber, OrderDate, Quantity, UnitPrice, Year, Month  FROM lakehouse.salesorders_partition;\n","\n","SET spark.sql.sources.partitionOverwriteMode=static;"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"sparksql"},"collapsed":false},"id":"99e36607-747d-45f2-8df6-72b3d6ef80bd"},{"cell_type":"code","source":["#########################################\n","# check_vorder\n","#########################################\n","def check_vorder(table_name_path):\n","    import os \n","\n","    if not os.path.exists(table_name_path):\n","        print(f'{os.path.basename(table_name_path)} does not exist')\n","        result = None  # Initialize the variable with a default value\n","\n","    else:\n","        import pyarrow.dataset as ds\n","        schema = ds.dataset(table_name_path).schema.metadata\n","        is_vorder = any(b'vorder' in key for key in schema.keys())\n","        if is_vorder:\n","            result = str(schema[b'com.microsoft.parquet.vorder.enabled'])\n","        else:\n","            result = \"Table is not V-ordered\"\n","\n","    return result"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"7544194e-b7d2-4cf3-ad29-13af63727693"},{"cell_type":"code","source":["table_list = spark.catalog.listTables()\n","\n","for table in table_list:\n","    print(table.name + ': ' +check_vorder(f'//lakehouse/default/Tables/{table.name}'))"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"9ffe8f92-b523-4a62-a802-00eb99a6dad1"},{"cell_type":"code","source":["%%sql\n","---------------------------------------------------\n","--4. Vacuum\n","--https://learn.microsoft.com/en-us/fabric/data-engineering/lakehouse-table-maintenance\n","---------------------------------------------------\n","VACUUM salesorders_partition_128\n"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"sparksql"}},"id":"f92c1484-4dc1-4f54-83ca-a6dac0f8384b"}],"metadata":{"language_info":{"name":"python"},"microsoft":{"language":"python"},"widgets":{},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"kernel_info":{"name":"synapse_pyspark"},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default"},"trident":{"lakehouse":{"default_lakehouse":"84dffe93-ada9-402a-a1c0-b841b4294651","default_lakehouse_name":"lakehouse","default_lakehouse_workspace_id":"bb3f0b26-c54b-4553-880c-fdd60e3815ec"}}},"nbformat":4,"nbformat_minor":5}